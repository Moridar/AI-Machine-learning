{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OHYKRHBrvVFG"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqtyB2kZvbGG"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SODOULDgvmT7"
      },
      "outputs": [],
      "source": [
        "# Read the data from the CSV file with read from Numpy\n",
        "data = np.genfromtxt(\"Salary_dataset.csv\", delimiter=\",\", skip_header=1)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_AKhsq3wbZj"
      },
      "outputs": [],
      "source": [
        "# Separate the features (YearsExperience) from the target variable (Salary)\n",
        "X = data[:, 1]\n",
        "y = data[:, 2]\n",
        "\n",
        "# X = X.reshape(-1, 1)\n",
        "print(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNKmC0-8ASF8"
      },
      "outputs": [],
      "source": [
        "#This time seaborn is forbidden, you have to find a library that works with numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y);\n",
        "plt.ylim(-5000, 140000)\n",
        "plt.xlim(0, 12);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX0jL2qC9LvH"
      },
      "outputs": [],
      "source": [
        "# Let's create a function that displays the point line with the bar.\n",
        "def visualize(theta, X, y):\n",
        "    plt.scatter(X, y)\n",
        "\n",
        "    plt.ylim(-5000, 140000)\n",
        "    plt.xlim(0, 12)\n",
        "    x_line = np.linspace(0, 12, 100)\n",
        "    y_line = theta[0] + theta[1] * x_line\n",
        "    plt.plot(x_line, y_line)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5e1X3ojyWTN"
      },
      "outputs": [],
      "source": [
        "# Ok, let's test our function now, you should get a result comparable to this one\n",
        "\n",
        "theta = np.zeros(2)\n",
        "visualize(theta, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4nI8REi8gsj"
      },
      "outputs": [],
      "source": [
        "# Create a function that multiplies each element of the matrix X by the slope of the model (theta[1]),\n",
        "#followed by the addition of the intercept of the model (theta[0]), thus producing the predictions of the simple linear regression model.\n",
        "\n",
        "def predict(X, theta):\n",
        "    return [X * theta[1] + theta[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf74-Nv58-F5"
      },
      "outputs": [],
      "source": [
        "def fit(X, y, theta, alpha, num_iters):\n",
        "    # Initialize some useful variables\n",
        "    m = X.shape[0]\n",
        "\n",
        "    # Loop over the number of iterations\n",
        "    for _ in range(num_iters):\n",
        "        predictions = predict(X, theta)\n",
        "        error = predictions - y\n",
        "        theta[0] -= alpha * (1/m) * np.sum(error)\n",
        "        theta[1] -= alpha * (1/m) * np.sum(X * error)\n",
        "        # Perform one iteration of gradient descent (i.e., update theta once)\n",
        "    return theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovlyLGQG9Fqw",
        "outputId": "0a25b78d-f9c1-40d9-c378-8234a9d68d93"
      },
      "outputs": [],
      "source": [
        "# To begin, we'll set alpha to 0.01 and num_iters to 1000\n",
        "\n",
        "theta = np.zeros(2)\n",
        "finetuned_theta = fit(X, y, theta, 0.01, 1000)\n",
        "print(finetuned_theta)\n",
        "\n",
        "#You should have a result similar to this one: [21912.58918422329, 9880.814004608217]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxwKUQhG9yuJ"
      },
      "outputs": [],
      "source": [
        "# Ok, let's test our function now, you should get a result comparable to this one\n",
        "\n",
        "theta = np.zeros(2)\n",
        "visualize(fit(X, y, theta, 0.01, 0), X, y)\n",
        "theta = np.zeros(2)\n",
        "visualize(fit(X, y, theta, 0.01, 1), X, y)\n",
        "theta = np.zeros(2)\n",
        "visualize(fit(X, y, theta, 0.01, 2), X, y)\n",
        "theta = np.zeros(2)\n",
        "visualize(fit(X, y, theta, 0.01, 3), X, y)\n",
        "theta = np.zeros(2)\n",
        "visualize(fit(X, y, theta, 0.01, 4), X, y)\n",
        "theta = np.zeros(2)\n",
        "visualize(fit(X, y, theta, 0.01, 1000), X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CfsYtv_907T"
      },
      "outputs": [],
      "source": [
        "def cost(X, y, theta):\n",
        "    # Calculate the difference between model predictions and actual target values\n",
        "    predictions = predict(X, theta)\n",
        "    error = y - predictions\n",
        "\n",
        "    # Calculate the squared sum of the loss and scale it by 1/(2 * number of samples)\n",
        "    cost = np.sum(error ** 2) * (1 / (2 * error.shape[1]))\n",
        "\n",
        "    # Return the computed cost as a measure of model fit\n",
        "    return cost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A8KQxD70LizQ"
      },
      "outputs": [],
      "source": [
        "# Test it with theta = [0,0]. You should get approximately 3251553638.\n",
        "\n",
        "cost_for_theta_zero = cost(X, y, [0, 0])\n",
        "print(cost_for_theta_zero)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlV8-dEKLnFU"
      },
      "outputs": [],
      "source": [
        "def fit_with_cost(X, y, theta, alpha, num_iters):\n",
        "    m = X.shape[0]  # Number of training examples\n",
        "    J_history = []  # List to store cost values at each iteration\n",
        "\n",
        "    # Loop over the specified number of iterations\n",
        "    for itr in range(num_iters):\n",
        "        # Calculate the loss (difference between predictions and actual values)\n",
        "        predictions = predict(X, theta)\n",
        "        error = y - predictions\n",
        "\n",
        "        # Update the temporary values of theta for both coefficients using the gradient descent formula\n",
        "\n",
        "        # Update the theta values\n",
        "\n",
        "        # Calculate and append the cost for the current theta values to the history list\n",
        "        cost = np.sum(error ** 2) * (1 / (2 * error.shape[1]))\n",
        "        J_history.append(cost)\n",
        "\n",
        "        # Perform one iteration of gradient descent (update theta values)\n",
        "        theta[0] += alpha * (1/m) * np.sum(error)\n",
        "        theta[1] += alpha * (1/m) * np.sum(X * error)\n",
        "\n",
        "    # Return the final theta values and the list of cost values over iterations\n",
        "    return (theta, J_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgdlGZmzL66I"
      },
      "outputs": [],
      "source": [
        "# First, we initialize theta to zero\n",
        "theta = np.zeros(2)\n",
        "\n",
        "# Start the training using your new function\n",
        "theta, J_history = fit_with_cost(X, y, theta, 0.001, 100)\n",
        "\n",
        "print(theta, J_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-3ruhFcN5cm"
      },
      "outputs": [],
      "source": [
        "#You have to reproduce this graph\n",
        "plt.plot(J_history)\n",
        "plt.title(\"Cost Value Over Iterations\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiIFDR-XOBgb",
        "outputId": "4c4f3001-b2da-458f-8b2b-5f7f4ec4dfb7"
      },
      "outputs": [],
      "source": [
        "# Years of experience of the person you want to predict the salary for\n",
        "years_experience = 10\n",
        "\n",
        "# Predict the salary\n",
        "predicted_salary = predict(years_experience, theta)[0]\n",
        "\n",
        "# Display the predicted salary\n",
        "print(\"Predicted salary for {} years of experience {}\".format(years_experience, predicted_salary))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
